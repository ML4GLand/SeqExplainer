{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bcb9a8f-21e5-439b-925a-9dbb8ada736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Basic import\n",
    "import eugene as eu\n",
    "eu.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbabdf06",
   "metadata": {},
   "source": [
    "# ISM attributions methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2cab005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: True\n",
      "Number of GPUs: 1\n",
      "Current GPU: 0\n",
      "GPUs: Quadro RTX 5000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from yuzu.utils import perturbations\n",
    "import eugene as eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d62cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22804d3c6763432d95aca3125faf7440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "One-hot encoding sequences:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sdata = eu.datasets.random1000()\n",
    "X_np = eu.pp.ohe_seqs(sdata[:10].seqs)\n",
    "model = eu.models.DeepBind(input_len=100, output_dim=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cf280b4",
   "metadata": {},
   "source": [
    "## Perturb seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd69152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_seq(seq):\n",
    "    \"\"\"Numpy version of perturbations\"\"\"\n",
    "    n_choices, seq_len = seq.shape\n",
    "    idxs = seq.argmax(axis=0)\n",
    "    n = seq_len * (n_choices - 1)\n",
    "    X = np.tile(seq, (n, 1))\n",
    "    X = X.reshape(n, n_choices, seq_len)\n",
    "    for k in range(1, n_choices):\n",
    "        i = np.arange(seq_len) * (n_choices - 1) + (k - 1)\n",
    "        X[i, idxs, np.arange(seq_len)] = 0\n",
    "        X[i, (idxs + k) % n_choices, np.arange(seq_len)] = 1\n",
    "    return X\n",
    "\n",
    "def perturb_seq_torch(seq):\n",
    "    \"\"\"Torch version of perturbations\"\"\"\n",
    "    n_choices, seq_len = seq.shape\n",
    "    idxs = seq.argmax(axis=0)\n",
    "    n = seq_len * (n_choices - 1)\n",
    "    X = torch.tile(seq, (n, 1))\n",
    "    X = X.reshape(n, n_choices, seq_len)\n",
    "    for k in range(1, n_choices):\n",
    "        i = torch.arange(seq_len) * (n_choices - 1) + (k - 1)\n",
    "        X[i, idxs, torch.arange(seq_len)] = 0\n",
    "        X[i, (idxs + k) % n_choices, torch.arange(seq_len)] = 1\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b732f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perturb_seq(X_np[0]).shape, eu.pp.decode_seqs(perturb_seq_torch(torch.from_numpy(X_np[0])).numpy())[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "845b1e81",
   "metadata": {},
   "source": [
    "## Peturb seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71ac4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_seqs(seqs):\n",
    "    n_seqs, n_choices, seq_len = seqs.shape\n",
    "    idxs = seqs.argmax(axis=1)\n",
    "    n = seq_len * (n_choices - 1)\n",
    "    X = np.tile(seqs, (n, 1, 1))\n",
    "    X = X.reshape(n, n_seqs, n_choices, seq_len).transpose(1, 0, 2, 3)\n",
    "    for i in range(n_seqs):\n",
    "        for k in range(1, n_choices):\n",
    "            idx = np.arange(seq_len) * (n_choices - 1) + (k - 1)\n",
    "\n",
    "            X[i, idx, idxs[i], np.arange(seq_len)] = 0\n",
    "            X[i, idx, (idxs[i] + k) % n_choices, np.arange(seq_len)] = 1\n",
    "    return X\n",
    "\n",
    "def perturb_seqs_torch(seqs):\n",
    "    n_seqs, n_choices, seq_len = seqs.shape\n",
    "    idxs = seqs.argmax(axis=1)\n",
    "    n = seq_len * (n_choices - 1)\n",
    "    X = torch.tile(seqs, (n, 1, 1))\n",
    "    X = X.reshape(n, n_seqs, n_choices, seq_len).permute(1, 0, 2, 3)\n",
    "    for i in range(n_seqs):\n",
    "        for k in range(1, n_choices):\n",
    "            idx = torch.arange(seq_len) * (n_choices - 1) + (k - 1)\n",
    "\n",
    "            X[i, idx, idxs[i], torch.arange(seq_len)] = 0\n",
    "            X[i, idx, (idxs[i] + k) % n_choices, torch.arange(seq_len)] = 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "936f9190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perturb_seqs(X_np).shape, perturb_seqs_torch(torch.from_numpy(X_np)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a6f36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eu.pp.decode_seqs(perturb_seqs_torch(torch.from_numpy(X_np)).numpy()[0])[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adf77c3f",
   "metadata": {},
   "source": [
    "## Naive ISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb05ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(y, reference):\n",
    "    return (y - reference).sum(axis=-1)\n",
    "def l1(y, reference):\n",
    "    return (y - reference).abs().sum(axis=-1)\n",
    "def l2(y, reference):\n",
    "    return torch.sqrt(torch.square(y - reference).sum(axis=-1))\n",
    "\n",
    "DIFF_REGISTRY = {\n",
    "    \"delta\": delta,\n",
    "    \"l1\": l1,\n",
    "    \"l2\": l2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0669476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = torch.tensor(X_np, dtype=torch.float32)\n",
    "model = eu.models.DeepBind(input_len=100, output_dim=2)\n",
    "target = 0\n",
    "batch_size = 10\n",
    "diff_type = \"delta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6fd2aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _naive_ism(\n",
    "    model, \n",
    "    inputs, \n",
    "    target=None, \n",
    "    batch_size=128, \n",
    "    diff_type=\"delta\", \n",
    "    device=\"cpu\"\n",
    "):\n",
    "    \n",
    "    # Get the number of sequences, choices, and sequence length\n",
    "    n_seqs, n_choices, seq_len = inputs.shape\n",
    "    n = seq_len * (n_choices - 1)\n",
    "    X_idxs = inputs.argmax(axis=1)\n",
    "\n",
    "    # If target not provided aggregate over all outputs\n",
    "    target = np.arange(model.output_dim) if target is None else target\n",
    "    \n",
    "    # Move the model to eval mode\n",
    "    model = model.eval()\n",
    "\n",
    "    # Get the reference output\n",
    "    reference = model(inputs)[:, target].unsqueeze(1)\n",
    "    batch_starts = np.arange(0, n, batch_size)\n",
    "    device=\"cpu\"\n",
    "\n",
    "    # Get the change in output for each perturbation\n",
    "    isms = []\n",
    "    for i in range(n_seqs):\n",
    "        X = perturb_seq_torch(inputs[i])\n",
    "        y = []\n",
    "        for start in batch_starts:\n",
    "            X_ = X[start : start + batch_size]\n",
    "            y_ = model(X_)[:, target].unsqueeze(1)\n",
    "            y.append(y_)\n",
    "            del X_\n",
    "        y = torch.cat(y)\n",
    "        ism = DIFF_REGISTRY[diff_type](y, reference[i])\n",
    "        isms.append(ism)\n",
    "\n",
    "    # Clean up the output to be (N, A, L)\n",
    "    isms = torch.stack(isms)\n",
    "    isms = isms.reshape(n_seqs, seq_len, n_choices - 1)\n",
    "    j_idxs = torch.arange(n_seqs * seq_len)\n",
    "    X_ism = torch.zeros(n_seqs * seq_len, n_choices, device=device)\n",
    "    for i in range(1, n_choices):\n",
    "        i_idxs = (X_idxs.flatten() + i) % n_choices\n",
    "        X_ism[j_idxs, i_idxs] = isms[:, :, i - 1].flatten()\n",
    "\n",
    "    X_ism = X_ism.reshape(n_seqs, seq_len, n_choices).permute(0, 2, 1)\n",
    "    return X_ism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f8c61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = _naive_ism(model, X_0, target=None, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87ec0a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_0[0][:, :5].permute(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4373d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = model(X_0[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af02bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = model(perturb_seq_torch(X_0[0])[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2aad4765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0003], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(new - orig).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90ea012d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0854e-04,  2.1504e-04,  1.2280e-04,  0.0000e+00],\n",
       "        [ 5.5820e-05,  5.4076e-05,  0.0000e+00,  8.4758e-05],\n",
       "        [-2.6880e-04,  0.0000e+00,  8.8975e-05,  2.8175e-04],\n",
       "        [-1.8227e-04, -4.0574e-04,  0.0000e+00, -1.4119e-05],\n",
       "        [ 0.0000e+00, -1.6875e-04,  7.9952e-03,  2.1660e-03]],\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][:, :5].permute(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "748d0a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TGCGAGGCCATGGCTCATGAGTTCTAAGGATGCGAATAACACAAAAAGCCGCGATCTTAAACGTTCTACACTTCTAAGGTCTGCATGAGCGAACCGAAAC'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu.pp.decode_seq(X_0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2691f626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TGGGAGGCCATGGCTCATGAGTTCTAAGGATGCGAATAACACAAAAAGCCGCGATCTTAAACGTTCTACACTTCTAAGGTCTGCATGAGCGAACCGAAAC'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu.pp.decode_seq(perturb_seq_torch(X_0[0]).detach().numpy()[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84aa8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Callable\n",
    "\n",
    "ISM_REGISTRY = {\n",
    "    \"NaiveISM\": _naive_ism,\n",
    "}\n",
    "\n",
    "def _ism_attributions(\n",
    "    model: torch.nn.Module, \n",
    "    inputs: Union[tuple, torch.Tensor],\n",
    "    method: Union[str, Callable],\n",
    "    target: int = None,\n",
    "    **kwargs\n",
    "):\n",
    "    attrs = ISM_REGISTRY[method](model=model, inputs=inputs, **kwargs)\n",
    "    return attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe0f741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eu.models.DeepBind(input_len=100, output_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6ef718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "explains = _ism_attributions(model=model, inputs=X_0, method=\"NaiveISM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e20f93",
   "metadata": {},
   "source": [
    "# Captum registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352203c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import InputXGradient, DeepLift, GradientShap, DeepLiftShap\n",
    "CAPTUM_REGISTRY = {\n",
    "    \"InputXGradient\": InputXGradient,\n",
    "    \"DeepLift\": DeepLift,\n",
    "    \"DeepLiftShap\": DeepLiftShap,\n",
    "    \"GradientShap\": GradientShap,\n",
    "\n",
    "}\n",
    "\n",
    "def _captum_attributions(\n",
    "    model: torch.nn.Module,\n",
    "    inputs: Union[tuple, torch.Tensor],\n",
    "    method: str,\n",
    "    target: int = 0,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if isinstance(inputs, np.ndarray):\n",
    "        inputs = torch.tensor(inputs)\n",
    "    attributor = CAPTUM_REGISTRY[method](model)\n",
    "    attrs = attributor.attribute(inputs=inputs, target=target, **kwargs)\n",
    "    return attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eu.models.DeepBind(input_len=100, output_dim=2, strand=\"ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f485f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transforms given, assuming just need to tensorize.\n"
     ]
    }
   ],
   "source": [
    "sdataset = sdata.to_dataset(target_keys=None, transform_kwargs={})\n",
    "sdataloader = sdataset.to_dataloader(batch_size=32, shuffle=False)\n",
    "batch = next(iter(sdataloader))\n",
    "forward, rev = batch[1], batch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c4edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.7/site-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "forward_ref = _get_reference(forward, \"gc\")\n",
    "reverse_ref = _get_reference(rev, \"gc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db167d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explains = _captum_attributions(model, (forward, rev), \"GradientShap\", target=1, baselines=(forward_ref, reverse_ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab50904",
   "metadata": {},
   "source": [
    "# Master attribution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models._base_models import BaseModel\n",
    "from eugene import settings\n",
    "from typing import Union, Callable\n",
    "\n",
    "ATTRIBUTIONS_REGISTRY = {\n",
    "    \"NaiveISM\": _ism_attributions,\n",
    "    \"InputXGradient\": _captum_attributions,\n",
    "    \"DeepLift\": _captum_attributions,\n",
    "    \"GradientShap\": _captum_attributions,\n",
    "    \"DeepLiftShap\": _captum_attributions,\n",
    "}\n",
    "\n",
    "def _model_to_device(model, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Get the model to the correct device\n",
    "    device = \"cuda\" if settings.gpus > 0 else \"cpu\" if device is None else device\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def attribute(\n",
    "    model: BaseModel,\n",
    "    inputs: torch.Tensor,\n",
    "    method: Union[str, Callable],\n",
    "    target: int = 0,\n",
    "    device: str = \"cpu\",\n",
    "    **kwargs\n",
    "):\n",
    "\n",
    "    # Put model on device\n",
    "    model = _model_to_device(model, device)\n",
    "\n",
    "    # Check kwargs for reference\n",
    "    if \"reference_type\" in kwargs:\n",
    "        ref_type = kwargs.pop(\"reference_type\")\n",
    "        kwargs[\"baselines\"] = _get_reference(inputs, ref_type)\n",
    "\n",
    "    # Get attributions\n",
    "    attr = ATTRIBUTIONS_REGISTRY[method](\n",
    "        model=model,\n",
    "        inputs=inputs,\n",
    "        method=method,\n",
    "        target=target,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    # Return attributions\n",
    "    return attr\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eu.models.DeepBind(input_len=100, output_dim=2, strand=\"ss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43493e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.7/site-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/vscode/.local/lib/python3.7/site-packages/captum/attr/_core/deep_lift.py:339: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  after the attribution is finished\"\"\"\n",
      "/home/vscode/.local/lib/python3.7/site-packages/captum/attr/_core/deep_lift.py:471: UserWarning: An invalid module MaxPool1d(kernel_size=85, stride=85, padding=0, dilation=1, ceil_mode=False) is detected. Saved gradients will\n",
      "                be used as the gradients of the module's input tensor.\n",
      "                See MaxPool1d as an example.\n",
      "  module\n",
      "/home/vscode/.local/lib/python3.7/site-packages/torch/nn/functional.py:651: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool1d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    }
   ],
   "source": [
    "explains = attribute(model=model, inputs=forward, method=\"DeepLiftShap\", target=0, baselines=\"gc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726845a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 100])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explains.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd32709",
   "metadata": {},
   "source": [
    "# Comparison to old implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7016ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eu.models.DeepBind(input_len=100, output_dim=2, strand=\"ss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2016f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transforms given, assuming just need to tensorize.\n"
     ]
    }
   ],
   "source": [
    "sdataset = sdata.to_dataset(target_keys=None, transform_kwargs={})\n",
    "sdataloader = sdataset.to_dataloader(batch_size=32, shuffle=False)\n",
    "batch = next(iter(sdataloader))\n",
    "forward, rev = batch[1], batch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81451f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.7/site-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "forward_ref = _get_reference(forward, \"zero\")\n",
    "reverse_ref = _get_reference(rev, \"zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f79ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old\n",
    "explains = eu.interpret.nn_explain(\n",
    "    model=model, \n",
    "    inputs=(forward, rev), \n",
    "    saliency_type=\"DeepLift\", \n",
    "    target=0, \n",
    "    baselines=(forward_ref, reverse_ref)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.7/site-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/vscode/.local/lib/python3.7/site-packages/captum/attr/_core/deep_lift.py:339: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  after the attribution is finished\"\"\"\n",
      "/home/vscode/.local/lib/python3.7/site-packages/captum/attr/_core/deep_lift.py:471: UserWarning: An invalid module MaxPool1d(kernel_size=85, stride=85, padding=0, dilation=1, ceil_mode=False) is detected. Saved gradients will\n",
      "                be used as the gradients of the module's input tensor.\n",
      "                See MaxPool1d as an example.\n",
      "  module\n",
      "/home/vscode/.local/lib/python3.7/site-packages/torch/nn/functional.py:651: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool1d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    }
   ],
   "source": [
    "explains_new = attribute(model=model, inputs=forward, method=\"DeepLift\", target=0, baselines=\"zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496e3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.00145747,\n",
       "        0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.00177175,  0.        ,  0.        , -0.00129909,\n",
       "       -0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.00035432,  0.00486775, -0.        ,  0.        ,  0.00358446,\n",
       "        0.        , -0.        ,  0.        ,  0.        , -0.00655105,\n",
       "        0.00031941,  0.        ,  0.00604295, -0.00020719,  0.        ,\n",
       "       -0.00688955,  0.        , -0.00539981, -0.00740858,  0.00150003,\n",
       "       -0.00288175,  0.00425521, -0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.00194549, -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.0007722 , -0.00143565,\n",
       "       -0.00253362,  0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.00087424,  0.        ,  0.00677859,\n",
       "        0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.00388851, -0.00518246,  0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.00109692,\n",
       "        0.        , -0.        , -0.0083457 , -0.        , -0.        ,\n",
       "       -0.        ,  0.00396699,  0.00778267,  0.        , -0.        ,\n",
       "        0.        ,  0.00756126,  0.        ,  0.        ,  0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explains_new[0].detach().cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7732aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.00145747,\n",
       "        0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.00177175,  0.        ,  0.        , -0.00129909,\n",
       "       -0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.00035432,  0.00486775, -0.        ,  0.        ,  0.00358446,\n",
       "        0.        , -0.        ,  0.        ,  0.        , -0.00655105,\n",
       "        0.00031941,  0.        ,  0.00604295, -0.00020719,  0.        ,\n",
       "       -0.00688955,  0.        , -0.00539981, -0.00740858,  0.00150003,\n",
       "       -0.00288175,  0.00425521, -0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.00194549, -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.0007722 , -0.00143565,\n",
       "       -0.00253362,  0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.00087424,  0.        ,  0.00677859,\n",
       "        0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.00388851, -0.00518246,  0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.00109692,\n",
       "        0.        , -0.        , -0.0083457 , -0.        , -0.        ,\n",
       "       -0.        ,  0.00396699,  0.00778267,  0.        , -0.        ,\n",
       "        0.        ,  0.00756126,  0.        ,  0.        ,  0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explains[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c13409",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c1bf1d0",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4706bce9",
   "metadata": {},
   "source": [
    "## Implement DeepLiftShap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaf2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _deepliftshap_explain(\n",
    "    model: torch.nn.Module, \n",
    "    inputs: tuple,\n",
    "    ref_type: str = \"zero\", \n",
    "    target: int = None, \n",
    "    device: str = \"cpu\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute DeepLIFT feature attribution scores using a model on a set of inputs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        PyTorch model to use for computing DeepLIFT scores.\n",
    "        Can be a EUGENe trained model or one you trained with PyTorch or PL.\n",
    "    inputs : tuple\n",
    "        Tuple of forward and reverse complement inputs to compute DeepLIFT scores on.\n",
    "        If the model is a ss model, then the scores will only be computed on the forward inputs.\n",
    "    ref_type: str\n",
    "        Type of reference to use for computing DeepLIFT scores. By default this is an all zeros reference,\n",
    "        but we also support a dinucleotide shuffled reference and one based on GC content\n",
    "    target: int\n",
    "        Index of the target class to compute scores for if there are multiple outputs. If there\n",
    "        is a single output, this should be None\n",
    "    device: str\n",
    "        Device to use for computing DeepLIFT scores.\n",
    "        EUGENe will always use a gpu if available\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    nd.array\n",
    "        Array of DeepLIFT scores\n",
    "    \"\"\"\n",
    "    # Run checks\n",
    "    if model.strand == \"ds\":\n",
    "        raise ValueError(\"DeepLift currently only works for ss and ts strand models\")\n",
    "    \n",
    "    # Get the model to the correct device\n",
    "    device = \"cuda\" if settings.gpus > 0 else \"cpu\" if device is None else device\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Set up the explainer\n",
    "    deepliftshap_explainer = DeepLiftShap(model)\n",
    "\n",
    "    # Prep the inputs\n",
    "    forward_inputs = inputs[0]\n",
    "    reverse_inputs = inputs[1]\n",
    "    if isinstance(forward_inputs, torch.Tensor):\n",
    "        forward_inputs = forward_inputs.detach().cpu().numpy()\n",
    "        reverse_inputs = reverse_inputs.detach().cpu().numpy() \n",
    "\n",
    "    # Prep the reference\n",
    "    if ref_type == \"zero\":\n",
    "        forward_ref = torch.zeros(forward_inputs.shape)\n",
    "        reverse_ref = torch.zeros(reverse_inputs.shape)\n",
    "    elif ref_type == \"shuffle\":\n",
    "        forward_ref = torch.tensor(dinuc_shuffle_seqs(forward_inputs))\n",
    "        if model.strand != \"ss\":\n",
    "            reverse_ref = torch.tensor(dinuc_shuffle_seqs(reverse_inputs))\n",
    "    elif ref_type == \"gc\":\n",
    "        forward_ref = torch.tensor([0.3, 0.2, 0.2, 0.3]).expand(forward.shape[0], forward.shape[2], 4).transpose(2, 1)\n",
    "        reverse_ref = forward_ref.clone()\n",
    "    elif callable(ref_type):\n",
    "        forward_ref = torch.tensor(ref_type(forward_inputs))\n",
    "        if model.strand != \"ss\":\n",
    "            reverse_ref = torch.tensor(ref_type(reverse_inputs))\n",
    "    forward_inputs = torch.tensor(forward_inputs).to(device)\n",
    "    forward_ref.to(device)\n",
    "\n",
    "    print(forward_inputs.shape, forward_ref.shape)\n",
    "    \n",
    "    # Compute the attribution scores\n",
    "    if model.strand == \"ss\":\n",
    "        attrs = deepliftshap_explainer.attribute(\n",
    "            forward_inputs,\n",
    "            baselines=(forward_ref),\n",
    "            target=target,\n",
    "        )\n",
    "        return attrs.to(\"cpu\").detach().numpy()\n",
    "    else:\n",
    "        reverse_inputs = torch.tensor(reverse_inputs).to(device)\n",
    "        reverse_ref.to(device)\n",
    "        attrs = deepliftshap_explainer.attribute(\n",
    "            (forward_inputs, reverse_inputs),\n",
    "            baselines=(forward_ref, reverse_ref),\n",
    "            target=target,\n",
    "        )\n",
    "        return (\n",
    "            attrs[0].to(\"cpu\").detach().numpy(),\n",
    "            attrs[1].to(\"cpu\").detach().numpy(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablate_first_base(seqs):\n",
    "    \"\"\"\n",
    "    Change the first base of each sequence in `seqs` to A, C, G, or T.\n",
    "    This is used for computing the DeepLIFT scores for the first base\n",
    "    \"\"\"\n",
    "    seqs[:, :, 0] = [0, 0, 0, 0]\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f9dd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0], dtype=int8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ablate_first_base(ohe_seqs)[0,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048cedb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transforms given, assuming just need to tensorize.\n"
     ]
    }
   ],
   "source": [
    "sdataset = sdata.to_dataset(target_keys=None, transform_kwargs={})\n",
    "sdataloader = sdataset.to_dataloader(batch_size=32, shuffle=False)\n",
    "batch = next(iter(sdataloader))\n",
    "forward, rev = batch[1], batch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad05edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eu.models.DeepBind(input_len=100, output_dim=2, strand=\"ts\", aggr=\"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d84b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 100]) torch.Size([32, 4, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.7/site-packages/captum/attr/_core/deep_lift.py:339: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  after the attribution is finished\"\"\"\n",
      "/home/vscode/.local/lib/python3.7/site-packages/captum/attr/_core/deep_lift.py:471: UserWarning: An invalid module MaxPool1d(kernel_size=85, stride=85, padding=0, dilation=1, ceil_mode=False) is detected. Saved gradients will\n",
      "                be used as the gradients of the module's input tensor.\n",
      "                See MaxPool1d as an example.\n",
      "  module\n",
      "/home/vscode/.local/lib/python3.7/site-packages/torch/nn/functional.py:651: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool1d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "A Module MaxPool1d(kernel_size=85, stride=85, padding=0, dilation=1, ceil_mode=False) was detected that does not contain some of the input/output attributes that are required for DeepLift computations. This can occur, for example, if your module is being used more than once in the network.Please, ensure that module is being used only once in the network.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "\u001b[0;32m/tmp/ipykernel_3136/575598594.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_deepliftshap_explain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mablate_first_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3136/2651573161.py\u001b[0m in \u001b[0;36m_deepliftshap_explain\u001b[0;34m(model, inputs, ref_type, target, device)\u001b[0m\n",
      "\u001b[1;32m     86\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mforward_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     87\u001b[0m             \u001b[0mbaselines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     89\u001b[0m         )\n",
      "\u001b[1;32m     90\u001b[0m         return (\n",
      "\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     33\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     34\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/captum/attr/_core/deep_lift.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, return_convergence_delta, custom_attribution_func)\u001b[0m\n",
      "\u001b[1;32m    864\u001b[0m                 \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_convergence_delta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    865\u001b[0m             ),\n",
      "\u001b[0;32m--> 866\u001b[0;31m             \u001b[0mcustom_attribution_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_attribution_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    867\u001b[0m         )\n",
      "\u001b[1;32m    868\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_convergence_delta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/captum/attr/_core/deep_lift.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, return_convergence_delta, custom_attribution_func)\u001b[0m\n",
      "\u001b[1;32m    360\u001b[0m                 \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    361\u001b[0m             )\n",
      "\u001b[0;32m--> 362\u001b[0;31m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_forward_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    363\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcustom_attribution_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiplies_by_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n",
      "\u001b[1;32m    117\u001b[0m         \u001b[0;31m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    118\u001b[0m         \u001b[0;31m# contains batch_size * #steps elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n",
      "\u001b[1;32m    275\u001b[0m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;32m    276\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 277\u001b[0;31m             allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/hooks.py\u001b[0m in \u001b[0;36mhook\u001b[0;34m(grad_input, _)\u001b[0m\n",
      "\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    109\u001b[0m             \u001b[0mgrad_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_with_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_tensors_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    112\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/captum/attr/_core/deep_lift.py\u001b[0m in \u001b[0;36m_backward_hook\u001b[0;34m(self, module, grad_input, grad_output)\u001b[0m\n",
      "\u001b[1;32m    506\u001b[0m                 \u001b[0;34m\"your module is being used more than once in the network.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    507\u001b[0m                 \u001b[0;34m\"Please, ensure that module is being used only once in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 508\u001b[0;31m                 \u001b[0;34m\"network.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    509\u001b[0m             )\n",
      "\u001b[1;32m    510\u001b[0m         multipliers = tuple(\n",
      "\n",
      "\u001b[0;31mRuntimeError\u001b[0m: A Module MaxPool1d(kernel_size=85, stride=85, padding=0, dilation=1, ceil_mode=False) was detected that does not contain some of the input/output attributes that are required for DeepLift computations. This can occur, for example, if your module is being used more than once in the network.Please, ensure that module is being used only once in the network."
     ]
    }
   ],
   "source": [
    "_deepliftshap_explain(model, (forward, rev), target=0, ref_type=ablate_first_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93244aa1",
   "metadata": {},
   "source": [
    "## Direct Captum usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826dfacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepliftshap_explainer = DeepLiftShap(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3eba85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.7/site-packages/captum/attr/_core/deep_lift.py:339: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  after the attribution is finished\"\"\"\n",
      "/home/vscode/.local/lib/python3.7/site-packages/captum/attr/_core/deep_lift.py:471: UserWarning: An invalid module MaxPool1d(kernel_size=85, stride=85, padding=0, dilation=1, ceil_mode=False) is detected. Saved gradients will\n",
      "                be used as the gradients of the module's input tensor.\n",
      "                See MaxPool1d as an example.\n",
      "  module\n",
      "/home/vscode/.local/lib/python3.7/site-packages/torch/nn/functional.py:651: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool1d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0015,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0066,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0033,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000, -0.0003,  0.0048,  ...,  0.0005,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0045,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0004,  0.0000,  0.0043],\n",
       "         [ 0.0000,  0.0000,  0.0027,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0037,  0.0000,  ...,  0.0000,  0.0016,  0.0000]]],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deepliftshap_explainer.attribute(\n",
    "    forward,\n",
    "    baselines=(forward_ref),\n",
    "    target=0,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 eugene_dev",
   "language": "python",
   "name": "eugene_dev"
  },
  "vscode": {
   "interpreter": {
    "hash": "f0aab14ae665ca4264878e5867720697752ca4d3a67458798aa51c276bf829a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
