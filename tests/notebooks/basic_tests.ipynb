{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import seqexplainer as se\n",
    "\n",
    "import seqpro as sp\n",
    "\n",
    "from eugene import models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = h5py.File(\"/cellar/users/aklie/projects/ML4GLand/use_cases/deAlmeida22/data/evo_aug/DeepSTARR_data.h5\", 'r')\n",
    "x_test = np.array(dataset['X_test']).astype(np.float32)\n",
    "y_test = np.array(dataset['Y_test']).astype(np.float32)\n",
    "dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41186, 4, 249), (41186, 2))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References for attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'seqexplainer._references' from '/cellar/users/aklie/projects/ML4GLand/SeqExplainer/seqexplainer/_references.py'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "from seqexplainer import _references as ref\n",
    "importlib.reload(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_np = x_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4, 249)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref.zero_ref_inputs(test_np).shape\n",
    "ref.random_ref_inputs(test_np).shape\n",
    "ref.shuffle_ref_inputs(test_np).shape\n",
    "ref.dinuc_shuffle_ref_inputs(test_np).shape\n",
    "ref.gc_ref_inputs(test_np).shape\n",
    "ref.gc_ref_inputs(test_np, bg=\"uniform\", uniform_dist=[0.3, 0.2, 0.3, 0.2]).shape\n",
    "ref.gc_ref_inputs(test_np, bg=\"batch\").shape\n",
    "ref.gc_ref_inputs(test_np, bg=\"seq\").shape\n",
    "ref.profile_ref_inputs(test_np).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4, 249)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref.get_reference(test_np, \"zero\").shape\n",
    "ref.get_reference(test_np, \"random\").shape\n",
    "ref.get_reference(test_np, \"shuffle\").shape\n",
    "ref.get_reference(test_np, \"dinuc_shuffle\").shape\n",
    "ref.get_reference(test_np, \"gc\").shape\n",
    "ref.get_reference(test_np, \"gc\", bg=\"uniform\", uniform_dist=[0.3, 0.2, 0.3, 0.2]).shape\n",
    "ref.get_reference(test_np, \"gc\", bg=\"batch\").shape\n",
    "ref.get_reference(test_np, \"gc\", bg=\"seq\").shape\n",
    "ref.get_reference(test_np, \"profile\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_np = (x_test[:100], x_test[100:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref.get_reference(test_np, \"zero\")\n",
    "ref.get_reference(test_np, \"random\")\n",
    "ref.get_reference(test_np, \"shuffle\")\n",
    "ref.get_reference(test_np, \"dinuc_shuffle\")\n",
    "ref.get_reference(test_np, \"gc\")\n",
    "ref.get_reference(test_np, \"gc\", bg=\"uniform\", uniform_dist=[0.3, 0.2, 0.3, 0.2])\n",
    "ref.get_reference(test_np, \"gc\", bg=\"batch\")\n",
    "ref.get_reference(test_np, \"gc\", bg=\"seq\")\n",
    "ref.get_reference(test_np, \"profile\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_seq = sp.decode_seq(test_np[0])\n",
    "decoded_ref = sp.decode_seq(refs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.26907631, 0.22891566, 0.15662651, 0.34538153]),\n",
       " array([0.26907631, 0.22891566, 0.15662651, 0.34538153]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.nucleotide_content_seq(decoded_seq), sp.nucleotide_content_seq(decoded_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_nucleotide_balance(test_np, refs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.DeepSTARR.load_from_checkpoint(\"/cellar/users/aklie/projects/ML4GLand/use_cases/deAlmeida22/models/eugene/DeepSTARR.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSTARR(\n",
       "  (train_metric): R2Score()\n",
       "  (val_metric): R2Score()\n",
       "  (test_metric): R2Score()\n",
       "  (conv1d_tower): Conv1DTower(\n",
       "    (layers): Sequential(\n",
       "      (0): Conv1d(4, 246, kernel_size=(7,), stride=(1,), padding=same)\n",
       "      (1): BatchNorm1d(246, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv1d(246, 60, kernel_size=(3,), stride=(1,), padding=same)\n",
       "      (5): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv1d(60, 60, kernel_size=(5,), stride=(1,), padding=same)\n",
       "      (9): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU()\n",
       "      (11): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (12): Conv1d(60, 120, kernel_size=(3,), stride=(1,), padding=same)\n",
       "      (13): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (14): ReLU()\n",
       "      (15): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (dense_block): DenseBlock(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=29400, out_features=256, bias=True)\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.4, inplace=False)\n",
       "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): Dropout(p=0.4, inplace=False)\n",
       "      (8): Linear(in_features=256, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 4, 249]), torch.Size([10, 2]))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_np = x_test[:10]\n",
    "test_y = torch.from_numpy(y_test[:10])\n",
    "test_torch = torch.from_numpy(test_np)\n",
    "test_torch.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Basset(\n",
    "    input_len=249,\n",
    "    output_dim=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'seqexplainer._attributions' from '/cellar/users/aklie/projects/ML4GLand/SeqExplainer/seqexplainer/_attributions.py'>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "from seqexplainer import _attributions as attribute \n",
    "importlib.reload(attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attribute.delta(model.predict(test_torch), test_y).shape\n",
    "#attribute.delta(model.predict(test_torch), test_y).shape\n",
    "#attribute.l2(model.predict(test_torch), test_y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Basset\n",
      "Sequence length: 249\n",
      "Output dimension: 2\n",
      "Strand: ss\n",
      "Task: multilabel_classification\n",
      "Aggregation of strands: None\n",
      "Loss function: binary_cross_entropy_with_logits\n",
      "Optimizer: Adam\n",
      "\tOptimizer parameters: {}\n",
      "\tOptimizer starting learning rate: 0.001\n",
      "Scheduler: None\n",
      "\tScheduler parameters: {}\n",
      "Metric: auroc\n",
      "\tMetric parameters: {'task': 'multilabel'}\n",
      "Seed: None\n",
      "Parameters summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  | Name         | Type        | Params\n",
       "---------------------------------------------\n",
       "0 | train_metric | AUROC       | 0     \n",
       "1 | val_metric   | AUROC       | 0     \n",
       "2 | test_metric  | AUROC       | 0     \n",
       "3 | conv1d_tower | Conv1DTower | 964 K \n",
       "4 | dense_block  | DenseBlock  | 48.4 M\n",
       "---------------------------------------------\n",
       "49.3 M    Trainable params\n",
       "0         Non-trainable params\n",
       "49.3 M    Total params\n",
       "197.331   Total estimated model params size (MB)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 13.9 GB\n",
      "Allocated: 2.1 GB\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "def report_gpu():\n",
    "   print(f\"Allocated: {round(torch.cuda.memory_allocated(0)/1024**3,1)} GB\") \n",
    "   gc.collect()\n",
    "   torch.cuda.empty_cache()\n",
    "   torch.cuda.synchronize()\n",
    "   print(f\"Allocated: {round(torch.cuda.memory_allocated(0)/1024**3,1)} GB\")\n",
    "report_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Basset(\n",
       "  (train_metric): AUROC()\n",
       "  (val_metric): AUROC()\n",
       "  (test_metric): AUROC()\n",
       "  (conv1d_tower): Conv1DTower(\n",
       "    (layers): Sequential(\n",
       "      (0): Conv1d(4, 300, kernel_size=(19,), stride=(1,), padding=(9,))\n",
       "      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv1d(300, 200, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "      (5): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv1d(200, 200, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (9): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU()\n",
       "      (11): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (dense_block): DenseBlock(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=48200, out_features=1000, bias=True)\n",
       "      (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=1000, out_features=164, bias=True)\n",
       "      (4): BatchNorm1d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=164, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: torch.Size([10, 4, 249]) cuda:0\n",
      "reference: torch.Size([10, 1, 2]) cpu\n",
      "inputs: torch.Size([10, 4, 249]) cpu\n",
      "batch_starts: [  0 128 256 384 512]\n",
      "Allocated: 2.1 GB\n",
      "input: torch.Size([4, 249]) cpu\n",
      "X: torch.Size([747, 4, 249]) cpu\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "y: torch.Size([747, 1, 2]) cpu\n",
      "ism: torch.Size([747, 1]) cpu\n",
      "inputs: torch.Size([10, 4, 249]) cpu\n",
      "input: torch.Size([4, 249]) cpu\n",
      "X: torch.Size([747, 4, 249]) cpu\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "y: torch.Size([747, 1, 2]) cpu\n",
      "ism: torch.Size([747, 1]) cpu\n",
      "inputs: torch.Size([10, 4, 249]) cpu\n",
      "input: torch.Size([4, 249]) cpu\n",
      "X: torch.Size([747, 4, 249]) cpu\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "y: torch.Size([747, 1, 2]) cpu\n",
      "ism: torch.Size([747, 1]) cpu\n",
      "inputs: torch.Size([10, 4, 249]) cpu\n",
      "input: torch.Size([4, 249]) cpu\n",
      "X: torch.Size([747, 4, 249]) cpu\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "y: torch.Size([747, 1, 2]) cpu\n",
      "ism: torch.Size([747, 1]) cpu\n",
      "inputs: torch.Size([10, 4, 249]) cpu\n",
      "input: torch.Size([4, 249]) cpu\n",
      "X: torch.Size([747, 4, 249]) cpu\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "y: torch.Size([747, 1, 2]) cpu\n",
      "ism: torch.Size([747, 1]) cpu\n",
      "inputs: torch.Size([10, 4, 249]) cpu\n",
      "input: torch.Size([4, 249]) cpu\n",
      "X: torch.Size([747, 4, 249]) cpu\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "y: torch.Size([747, 1, 2]) cpu\n",
      "ism: torch.Size([747, 1]) cpu\n",
      "inputs: torch.Size([10, 4, 249]) cpu\n",
      "input: torch.Size([4, 249]) cpu\n",
      "X: torch.Size([747, 4, 249]) cpu\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "y: torch.Size([747, 1, 2]) cpu\n",
      "ism: torch.Size([747, 1]) cpu\n",
      "inputs: torch.Size([10, 4, 249]) cpu\n",
      "input: torch.Size([4, 249]) cpu\n",
      "X: torch.Size([747, 4, 249]) cpu\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "y: torch.Size([747, 1, 2]) cpu\n",
      "ism: torch.Size([747, 1]) cpu\n",
      "inputs: torch.Size([10, 4, 249]) cpu\n",
      "input: torch.Size([4, 249]) cpu\n",
      "X: torch.Size([747, 4, 249]) cpu\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "y: torch.Size([747, 1, 2]) cpu\n",
      "ism: torch.Size([747, 1]) cpu\n",
      "inputs: torch.Size([10, 4, 249]) cpu\n",
      "input: torch.Size([4, 249]) cpu\n",
      "X: torch.Size([747, 4, 249]) cpu\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "model: cuda:0\n",
      "Allocated: 2.1 GB\n",
      "y: torch.Size([747, 1, 2]) cpu\n",
      "ism: torch.Size([747, 1]) cpu\n",
      "inputs: torch.Size([10, 4, 249]) cpu\n",
      "isms: torch.Size([10, 747, 1]) cpu\n"
     ]
    }
   ],
   "source": [
    "naive_ism_output = attribute._naive_ism(model.to(\"cuda\"), test_torch.to(\"cuda\"), device=\"cuda\", batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  0.0000e+00, -8.5846e-02,  ..., -2.3594e-02,\n",
       "          -2.8929e-02,  2.3758e-02],\n",
       "         [-9.1438e-02, -1.2441e-01,  0.0000e+00,  ..., -1.1276e-02,\n",
       "           1.1793e-01,  3.2274e-03],\n",
       "         [-5.5144e-03, -4.5820e-02,  9.2206e-02,  ..., -2.4472e-02,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-3.4599e-02,  2.1148e-03, -1.5401e-02,  ...,  0.0000e+00,\n",
       "           2.8023e-02, -7.5651e-02]],\n",
       "\n",
       "        [[ 0.0000e+00, -2.7673e-02, -1.5014e-02,  ...,  3.1489e-02,\n",
       "          -1.2122e-01,  0.0000e+00],\n",
       "         [-1.0497e-02, -3.4869e-02, -1.1718e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  1.8534e-01],\n",
       "         [ 7.6455e-02,  2.0381e-02,  0.0000e+00,  ...,  7.2406e-02,\n",
       "          -5.4008e-02,  2.3837e-02],\n",
       "         [-6.6376e-02,  0.0000e+00, -1.7447e-01,  ..., -6.3656e-02,\n",
       "          -1.6397e-01,  8.0734e-02]],\n",
       "\n",
       "        [[-3.7031e-02,  1.2567e-01, -1.0226e-01,  ..., -5.6308e-02,\n",
       "           4.8430e-02, -1.0986e-01],\n",
       "         [-5.6239e-02,  1.1346e-02, -3.2659e-02,  ..., -7.0306e-03,\n",
       "           5.5102e-02,  0.0000e+00],\n",
       "         [ 4.8038e-02,  0.0000e+00, -4.5349e-02,  ..., -3.2347e-02,\n",
       "           1.3604e-02, -7.0922e-02],\n",
       "         [ 0.0000e+00,  2.7450e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -1.4069e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0000e+00, -3.7781e-02, -1.7139e-02,  ...,  0.0000e+00,\n",
       "           4.8782e-02,  6.5105e-03],\n",
       "         [-2.8645e-03,  6.4858e-03,  0.0000e+00,  ..., -7.1723e-02,\n",
       "          -4.2784e-02,  0.0000e+00],\n",
       "         [-5.6381e-03,  0.0000e+00,  1.3377e-02,  ...,  8.8763e-02,\n",
       "           9.3369e-02,  1.3335e-02],\n",
       "         [-3.3523e-02, -1.5612e-02, -3.6755e-02,  ..., -1.4958e-02,\n",
       "           0.0000e+00, -8.4293e-02]],\n",
       "\n",
       "        [[-1.1360e-03, -4.4540e-02, -1.5592e-01,  ...,  1.7443e-02,\n",
       "          -4.1199e-02, -4.3228e-02],\n",
       "         [-5.3802e-02, -7.9118e-03, -2.5752e-02,  ..., -9.0681e-02,\n",
       "           3.7778e-02,  0.0000e+00],\n",
       "         [ 2.2355e-02, -3.0519e-03, -9.8235e-02,  ..., -9.1608e-02,\n",
       "           6.2961e-02,  1.4040e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -2.2195e-02]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00, -8.0089e-02,  ..., -3.0309e-05,\n",
       "           4.8539e-02,  4.3427e-02],\n",
       "         [-1.9140e-02, -1.1417e-01,  0.0000e+00,  ..., -3.7024e-02,\n",
       "           8.1699e-02,  0.0000e+00],\n",
       "         [ 2.8898e-02,  2.6971e-03,  5.2088e-02,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -4.8809e-02],\n",
       "         [-1.5993e-02, -3.1406e-03,  1.2101e-01,  ...,  2.9769e-02,\n",
       "          -8.3106e-02, -1.5170e-01]]], grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_ism_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: torch.Size([10, 4, 249]) cpu\n",
      "10 4 249 747\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1476560/3076623641.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnaive_ism_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_naive_ism\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_torch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnaive_ism_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ML4GLand/SeqExplainer/seqexplainer/_attributions.py\u001b[0m in \u001b[0;36m_naive_ism\u001b[0;34m(model, inputs, target, batch_size, diff_type, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# Get the reference outputs for each sequence in the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reference:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inputs:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ML4GLand/EUGENe/eugene/models/_basic_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_rev_comp)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_rev_comp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d_tower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d_tower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ML4GLand/EUGENe/eugene/models/base/_towers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBiConv1DTower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    308\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    309\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0;32m--> 310\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "naive_ism_output = attribute._naive_ism(model, test_torch, target=0)\n",
    "naive_ism_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_ism_output = attribute._naive_ism(model, test_torch, target=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute.delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se.attribute(model, test_np, method=\"DeepLift\", reference_type=\"dinuc_shuffle\", target=0, batch_size=128, device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4, 249)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref.zero_ref_inputs(test_np).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1416501/2048557899.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# ref.dinuc_shuffle_ref_inputs(test_torch).shape TODO: fix this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc_ref_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uniform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniform_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc_ref_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_torch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uniform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniform_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ML4GLand/SeqExplainer/seqexplainer/_references.py\u001b[0m in \u001b[0;36mgc_ref_inputs\u001b[0;34m(inputs, bg, uniform_dist)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m\"uniform\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniform_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "ref.zero_ref_inputs(test_np).shape\n",
    "ref.zero_ref_inputs(test_torch).shape\n",
    "\n",
    "ref.random_ref_inputs(test_np).shape\n",
    "ref.random_ref_inputs(test_torch).shape\n",
    "\n",
    "ref.shuffle_ref_inputs(test_np).shape\n",
    "ref.shuffle_ref_inputs(test_torch).shape\n",
    "\n",
    "ref.dinuc_shuffle_ref_inputs(test_np).shape\n",
    "# ref.dinuc_shuffle_ref_inputs(test_torch).shape TODO: fix this\n",
    "\n",
    "ref.gc_ref_inputs(test_np, bg=\"uniform\", uniform_dist=[0.3, 0.2, 0.2, 0.3]).shape\n",
    "ref.gc_ref_inputs(test_torch, bg=\"uniform\", uniform_dist=[0.3, 0.2, 0.2, 0.3]).shape\n",
    "\n",
    "ref.gc_ref_inputs(test_np, bg=\"batch\").shape\n",
    "ref.gc_ref_inputs(test_torch, bg=\"batch\").shape\n",
    "\n",
    "# ref.gc_ref_inputs(test_np, bg=\"seq\").shape TODO: fix this\n",
    "ref.gc_ref_inputs(test_torch, bg=\"seq\").shape\n",
    "\n",
    "ref.profile_ref_inputs(test_torch).shape\n",
    "# ref.profile_ref_inputs(test_np).shape TODO: fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 4, 249])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref.get_reference(test_torch, \"zero\", \"cpu\").shape\n",
    "ref.get_reference(test_np, \"zero\", \"cpu\").shape\n",
    "ref.get_reference(test_torch, \"zero\", \"cuda\").shape\n",
    "ref.get_reference(test_np, \"zero\", \"cuda\").shape\n",
    "\n",
    "ref.get_reference(test_torch, \"random\", \"cpu\").shape\n",
    "ref.get_reference(test_np, \"random\", \"cpu\").shape\n",
    "ref.get_reference(test_torch, \"random\", \"cuda\").shape\n",
    "ref.get_reference(test_np, \"random\", \"cuda\").shape\n",
    "\n",
    "ref.get_reference(test_torch, \"shuffle\", \"cpu\").shape\n",
    "ref.get_reference(test_np, \"shuffle\", \"cpu\").shape\n",
    "ref.get_reference(test_torch, \"shuffle\", \"cuda\").shape\n",
    "ref.get_reference(test_np, \"shuffle\", \"cuda\").shape\n",
    "\n",
    "ref.get_reference(test_np, \"dinuc_shuffle\", \"cpu\").shape \n",
    "# ref.get_reference(test_torch, \"dinuc_shuffle\", \"cpu\").shape\n",
    "ref.get_reference(test_np, \"dinuc_shuffle\", \"cuda\").shape\n",
    "# ref.get_reference(test_torch, \"dinuc_shuffle\", \"cuda\").shape\n",
    "\n",
    "ref.get_reference(test_torch, \"gc\", \"cpu\").shape\n",
    "ref.get_reference(test_np, \"gc\", \"cpu\").shape\n",
    "ref.get_reference(test_torch, \"gc\", \"cuda\").shape\n",
    "ref.get_reference(test_np, \"gc\", \"cuda\").shape\n",
    "\n",
    "ref.get_reference(test_torch, \"profile\", \"cpu\").shape\n",
    "# ref.get_reference(test_np, \"profile\", \"cpu\").shape\n",
    "# ref.get_reference(test_torch, \"profile\", \"cuda\").shape\n",
    "# ref.get_reference(test_np, \"profile\", \"cuda\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333422eacba8457eb624a06f60b54ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Computing attributions on batches of size 128', max=1.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1416501/3078780733.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"DeepLift\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dinuc_shuffle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/ML4GLand/SeqExplainer/seqexplainer/_attributions.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(model, inputs, method, reference_type, target, batch_size, device)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreference_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"baselines\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# Get attributions and append\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ML4GLand/SeqExplainer/seqexplainer/_references.py\u001b[0m in \u001b[0;36mget_reference\u001b[0;34m(inputs, method, device)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mREFERENCE_REGISTRY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mREFERENCE_REGISTRY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ML4GLand/SeqExplainer/seqexplainer/_references.py\u001b[0m in \u001b[0;36mdinuc_shuffle_ref_inputs\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdinuc_shuffle_seqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 eugene_dev",
   "language": "python",
   "name": "eugene_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
