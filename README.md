[![PyPI version](https://badge.fury.io/py/seqexplainer.svg)](https://badge.fury.io/py/seqexplainer)
![PyPI - Downloads](https://img.shields.io/pypi/dm/seqexplainer)

<img src="docs/_static/SeqExplainer_logo.png" alt="SeqExplainer Logo" width=350>

# SeqExplainer -- Interpreting sequence-to-function machine learning models
Interpreting models is a critical importance in regulatory genomics, but is often made challenging by the complexity of neural networks and methods for their interpretation. There is a need for tools that allow researchers to experiment with different datasets and interpretability methods in the space of machine learning for genomics. We created SeqExplainer to make various post-hoc interpretation strategies accessible to most PyTorch model trained on one-hot encoded genomic sequences.  SeqExplainer currently provides functionality for filter interpretation, attribution analysis, in silico experimentation, and sequence generation.

# Usage tutorials
You can find several tutorials on how to use SeqExplainer for your models at the ML4GLand [tutorials repo](https://github.com/ML4GLand/tutorials/tree/main/seqexplainer). 

# Readthedocs coming soon
We are currently working on the documentation for SeqExplainer. It will be available at [seqexplainer.readthedocs.io](https://seqexplainer.readthedocs.io/en/latest/). Stay tuned!
